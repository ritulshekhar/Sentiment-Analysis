{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d3fb2e-3946-49de-89c8-08846f077109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['clean_text', 'category'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/twitter_dataset.csv')\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1517be8f-ec12-418f-b0db-2e5a57186ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pickle\n",
    "from utils.preprocessing import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b2edc7-20b5-478b-bc28-bbb885c02b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>modi promised minimum government maximum gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk nonsense continue drama vote modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>say vote modi welcome bjp told rahul main camp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asking supporters prefix chowkidar names modi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>answer among powerful world leader today trump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0  when modi promised “minimum government maximum...       -1.0   \n",
       "1  talk all the nonsense and continue all the dra...        0.0   \n",
       "2  what did just say vote for modi  welcome bjp t...        1.0   \n",
       "3  asking his supporters prefix chowkidar their n...        1.0   \n",
       "4  answer who among these the most powerful world...        1.0   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  modi promised minimum government maximum gover...  \n",
       "1             talk nonsense continue drama vote modi  \n",
       "2  say vote modi welcome bjp told rahul main camp...  \n",
       "3  asking supporters prefix chowkidar names modi ...  \n",
       "4  answer among powerful world leader today trump...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/twitter_dataset.csv') \n",
    "df = df[['clean_text', 'category']]            \n",
    "df = df.rename(columns={'clean_text': 'text', 'category': 'sentiment'})  \n",
    "df['cleaned_text'] = df['text'].astype(str).apply(clean_text)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0c4dd2-9787-4ba9-9f6f-f337fc876dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sentiment values: [-1.  0.  1.]\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      " 1.0    72250\n",
      " 0.0    55213\n",
      "-1.0    35510\n",
      "Name: count, dtype: int64\n",
      "Final label distribution:\n",
      "label\n",
      "2    72250\n",
      "1    55213\n",
      "0    35510\n",
      "Name: count, dtype: int64\n",
      "Label mapping verification:\n",
      "  -1.0 -> 0.0\n",
      "  0.0 -> 1.0\n",
      "  1.0 -> 2.0\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['sentiment'])\n",
    "\n",
    "# Debug: Check unique sentiment values\n",
    "print(\"Unique sentiment values:\", df['sentiment'].unique())\n",
    "print(\"Sentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# Create label mapping\n",
    "label_map = {-1.0: 0, 0.0: 1, 1.0: 2}\n",
    "df['label'] = df['sentiment'].map(label_map)\n",
    "\n",
    "# Check for unmapped values\n",
    "unmapped_sentiments = df[df['label'].isna()]['sentiment'].unique()\n",
    "if len(unmapped_sentiments) > 0:\n",
    "    print(f\"WARNING: Found unmapped sentiment values: {unmapped_sentiments}\")\n",
    "\n",
    "# Drop rows with missing labels\n",
    "df = df.dropna(subset=['label'])\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Final check\n",
    "print(\"Final label distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(\"Label mapping verification:\")\n",
    "for sentiment, label in df[['sentiment', 'label']].drop_duplicates().values:\n",
    "    print(f\"  {sentiment} -> {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd66c95a-5ce0-4ca2-b360-3a71da94cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['cleaned_text'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['cleaned_text'])\n",
    "padded = pad_sequences(sequences, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27e59c9-2239-4c0d-977a-1acbb53160ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 130378\n",
      "Test set size: 32595\n",
      "Training set label distribution:\n",
      "label\n",
      "0    28408\n",
      "1    44170\n",
      "2    57800\n",
      "Name: count, dtype: int64\n",
      "Test set label distribution:\n",
      "label\n",
      "0     7102\n",
      "1    11043\n",
      "2    14450\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded, df['label'], \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df['label']  # Ensure balanced split\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(\"Training set label distribution:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "print(\"Test set label distribution:\")\n",
    "print(pd.Series(y_test).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e761e365-0560-4151-91ea-7325b2425e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritulshekhar/venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dropout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m model = Sequential([\n\u001b[32m      2\u001b[39m     Embedding(input_dim=\u001b[32m10000\u001b[39m, output_dim=\u001b[32m128\u001b[39m, input_length=\u001b[32m100\u001b[39m, mask_zero=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m      3\u001b[39m     SimpleRNN(\u001b[32m128\u001b[39m, return_sequences=\u001b[38;5;28;01mTrue\u001b[39;00m, dropout=\u001b[32m0.3\u001b[39m, recurrent_dropout=\u001b[32m0.3\u001b[39m),\n\u001b[32m      4\u001b[39m     SimpleRNN(\u001b[32m64\u001b[39m, dropout=\u001b[32m0.3\u001b[39m, recurrent_dropout=\u001b[32m0.3\u001b[39m),\n\u001b[32m      5\u001b[39m     Dense(\u001b[32m32\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mDropout\u001b[49m(\u001b[32m0.5\u001b[39m),\n\u001b[32m      7\u001b[39m     Dense(\u001b[32m3\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m ])\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[32m     11\u001b[39m optimizer = Adam(learning_rate=\u001b[32m0.001\u001b[39m)  \u001b[38;5;66;03m# Lower learning rate\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Dropout' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, mask_zero=True),  # Removed input_length\n",
    "    SimpleRNN(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3),\n",
    "    SimpleRNN(64, dropout=0.3, recurrent_dropout=0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Use lower learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64cde4b-f5f6-4937-bb8d-d83cde0ced62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(f\"Class weights: {class_weights_dict}\")\n",
    "\n",
    "# Add callbacks for better training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model with callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197cf6e-e243-42f6-ab4f-65b157d02273",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c05349-97c0-4095-a8d6-660d0c43e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/sentiment_model.keras\")\n",
    "\n",
    "with open(\"model/tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef47a52-eed3-41e8-8d1f-4b79a4ccdc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(text, debug=False):\n",
    "    \"\"\"\n",
    "    Enhanced prediction function\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        print(f\"Original text: '{text}'\")\n",
    "    \n",
    "    # Clean the text\n",
    "    cleaned = clean_text(text)\n",
    "    if debug:\n",
    "        print(f\"Cleaned text: '{cleaned}'\")\n",
    "    \n",
    "    # Handle empty text\n",
    "    if not cleaned.strip():\n",
    "        return \"Neutral\" if not debug else (\"Neutral\", 0.33)\n",
    "    \n",
    "    # Convert to sequence\n",
    "    seq = tokenizer.texts_to_sequences([cleaned])\n",
    "    if debug:\n",
    "        print(f\"Sequence: {seq}\")\n",
    "    \n",
    "    # Check for empty sequence\n",
    "    if not seq[0]:\n",
    "        return \"Neutral\" if not debug else (\"Neutral\", 0.33)\n",
    "    \n",
    "    # Pad sequence\n",
    "    padded_seq = pad_sequences(seq, maxlen=100, padding='post')\n",
    "    \n",
    "    # Make prediction\n",
    "    pred_probs = model.predict(padded_seq, verbose=0)\n",
    "    pred_class = pred_probs.argmax()\n",
    "    confidence = pred_probs.max()\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Prediction probabilities: {pred_probs[0]}\")\n",
    "        print(f\"Predicted class: {pred_class}\")\n",
    "        print(f\"Confidence: {confidence:.3f}\")\n",
    "    \n",
    "    labels = ['Negative', 'Neutral', 'Positive']\n",
    "    sentiment = labels[pred_class]\n",
    "    \n",
    "    if debug:\n",
    "        return sentiment, confidence\n",
    "    else:\n",
    "        return sentiment\n",
    "\n",
    "# Test predictions\n",
    "test_texts = [\n",
    "    \"I absolutely love this product!\",\n",
    "    \"It was terrible and boring.\",\n",
    "    \"It's fine, not too bad.\",\n",
    "    \"This is amazing and wonderful!\",\n",
    "    \"I hate this so much, it's awful\",\n",
    "    \"It's okay, nothing special\"\n",
    "]\n",
    "\n",
    "print(\"=== TESTING PREDICTIONS ===\")\n",
    "for text in test_texts:\n",
    "    result = predict_single(text, debug=True)\n",
    "    if isinstance(result, tuple):\n",
    "        sentiment, confidence = result\n",
    "        print(f\"Final Result: {sentiment} (Confidence: {confidence:.3f})\")\n",
    "    else:\n",
    "        print(f\"Final Result: {result}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbd356-dec8-490e-9a48-8d1361264b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== MODEL EVALUATION ===\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "\n",
    "# Classification report\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=labels))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "print(cm)\n",
    "\n",
    "# Check prediction distribution\n",
    "print(\"\\nPrediction Distribution:\")\n",
    "unique, counts = np.unique(y_pred_classes, return_counts=True)\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Class {i} ({labels[i]}): {count} predictions ({count/len(y_pred_classes)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59bf84-ac2e-4552-a097-bfefdc03a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce1fb5-2a03-4b19-ac3f-6529809b57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be341c-c99a-4f22-bfd2-740a396b86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_text(\"I love this!\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582493fc-1e58-4a90-93f3-75b1ad1694b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809082d-5f25-43f4-ad36-1064677c5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tokenizer vocabulary size: {len(tokenizer.word_index)}\")\n",
    "print(f\"Sample word indices: {dict(list(tokenizer.word_index.items())[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c26bf62-3730-4d01-b5db-23aace65fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249641b-e290-4ac1-b493-b9733686151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(text):\n",
    "    cleaned = clean_text(text)\n",
    "    seq = tokenizer.texts_to_sequences([cleaned])\n",
    "    padded_seq = pad_sequences(seq, maxlen=100)\n",
    "    pred = model.predict(padded_seq)\n",
    "    print(\"Prediction probabilities:\", pred)\n",
    "    return ['Negative', 'Neutral', 'Positive'][pred.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697e89d-f814-4d56-89e4-379bb134cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(df['cleaned_text'][i], \"=>\", df['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9c1ea-d9be-4dba-ba2d-3a81c580e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
